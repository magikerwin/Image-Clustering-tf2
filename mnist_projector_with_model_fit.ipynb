{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist_projector_with_model_fit.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjjPp7HW-l1I"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "print('TF version:', tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9lG0IqtcBGj"
      },
      "source": [
        "# Training Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m95EzXMyBGhj"
      },
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDhAL9iYBFqg"
      },
      "source": [
        "LEARNING_RATE = 1e-2\n",
        "BATCH_SIZE = 128\n",
        "NUM_EPOCHS = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JMPxut4715n"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJTQsjdx6zay"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Data normalization\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Adds channel dim for conv layer\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytJ-nkNx94qi"
      },
      "source": [
        "## Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_bFQ20m9RpH"
      },
      "source": [
        "classifier = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Input((28, 28, 1), name='input'),\n",
        "  tf.keras.layers.Conv2D(8, 3, 2, activation='relu', name='conv1'),\n",
        "  tf.keras.layers.Conv2D(16, 3, 2, activation='relu', name='conv2'),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu', name='fc1'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(64, activation='relu', name='fc2'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10, activation='softmax', name='fc3')\n",
        "], name='classifier')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCQdGo5i9zHJ"
      },
      "source": [
        "classifier.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dTz4KQP-DSK"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1tc5FJ891Xf"
      },
      "source": [
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "\n",
        "classifier.compile(optimizer=optimizer,\n",
        "                   loss=loss_fn,\n",
        "                   metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJ1t51uL-QYo"
      },
      "source": [
        "classifier.fit(x=x_train,\n",
        "               y=y_train,\n",
        "               batch_size=BATCH_SIZE,\n",
        "               epochs=NUM_EPOCHS,\n",
        "               validation_data=(x_test, y_test),\n",
        "               validation_batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tco_tcGMAT-j"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rlkgs-C-TP0"
      },
      "source": [
        "eval_loss, eval_acc = classifier.evaluate(x_test, y_test, verbose=2)\n",
        "print('eval_loss:', eval_loss)\n",
        "print('eval_acc:', eval_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwngEPOqcGuc"
      },
      "source": [
        "# Visualization using Embedding Projector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7q9UM_b2-_FI"
      },
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from tensorboard.plugins import projector\n",
        "\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VgGdKdxe90p"
      },
      "source": [
        "## Dataset for Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buW4xevhfAHl"
      },
      "source": [
        "VISUALIZATION_COUNT = 900\n",
        "\n",
        "x_test_ = x_test[:VISUALIZATION_COUNT]\n",
        "y_test_ = y_test[:VISUALIZATION_COUNT]\n",
        "print(x_test_.shape)\n",
        "print(y_test_.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPJE4Lt8fHPb"
      },
      "source": [
        "## Feature Extractor Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNv4lqRwcmK3"
      },
      "source": [
        "feature_extractor = tf.keras.Model(inputs=[classifier.input], \n",
        "                                   outputs=[classifier.get_layer('fc2').output])\n",
        "print(feature_extractor.output.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KcxPO-vfcN0"
      },
      "source": [
        "## Embedding Projector Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wp3G-dQucdPR"
      },
      "source": [
        "# Sets up a logs directory for Tensorboard\n",
        "log_dir='logs/mnist-embeddings'\n",
        "if not os.path.exists(log_dir):\n",
        "    os.makedirs(log_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mUkUkt2cyXB"
      },
      "source": [
        "# Saves labels to metadata.tsv\n",
        "classes = ['Zero', 'One', 'Two', 'Three', 'Four', 'Five', 'Six', 'Seven',\n",
        "           'Eight', 'Nine']\n",
        "with open(os.path.join(log_dir, 'metadata.tsv'), \"w\") as f:\n",
        "  for y in y_test_:\n",
        "    f.write(\"{}\\n\".format(classes[y]))\n",
        "\n",
        "\n",
        "images_pil = []\n",
        "for x, y in zip(x_test_, y_test_):\n",
        "  img_pil = Image.fromarray((x[..., 0] * 255).astype(np.uint8))\n",
        "  images_pil.append(img_pil)\n",
        "\n",
        "# Saves sprite image\n",
        "one_square_size = int(np.ceil(np.sqrt(VISUALIZATION_COUNT)))\n",
        "master_width = 28 * one_square_size\n",
        "master_height = 28 * one_square_size\n",
        "spriteimage = Image.new(\n",
        "    mode='RGB',\n",
        "    size=(master_width, master_height),\n",
        "    color=(0,0,0)  # fully transparent\n",
        ")\n",
        "\n",
        "for count, image in enumerate(images_pil):\n",
        "    div, mod = divmod(count, one_square_size)\n",
        "    h_loc = 28 * div\n",
        "    w_loc = 28 * mod\n",
        "    spriteimage.paste(image, (w_loc, h_loc))\n",
        "\n",
        "spriteimage.convert('RGB').save(os.path.join(log_dir, 'sprite.jpg'))\n",
        "spriteimage"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fmsJtoTdHV4"
      },
      "source": [
        "# Save the weights we want to analyze as a variable.\n",
        "features = feature_extractor(x_test_, training=False)\n",
        "features_var = tf.Variable(features)\n",
        "print(features_var.shape)\n",
        "\n",
        "# Create a checkpoint from embedding, the filename and key are the\n",
        "# name of the tensor.\n",
        "checkpoint = tf.train.Checkpoint(embedding=features_var)\n",
        "checkpoint.save(os.path.join(log_dir, \"embedding.ckpt\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0s-FAay6eF_L"
      },
      "source": [
        "# Sets up config\n",
        "config = projector.ProjectorConfig()\n",
        "embedding = config.embeddings.add()\n",
        "\n",
        "# The name of the tensor will be suffixed by `/.ATTRIBUTES/VARIABLE_VALUE`.\n",
        "embedding.tensor_name = \"embedding/.ATTRIBUTES/VARIABLE_VALUE\"\n",
        "embedding.metadata_path = 'metadata.tsv'\n",
        "embedding.sprite.image_path = 'sprite.jpg'\n",
        "embedding.sprite.single_image_dim.extend([28, 28])\n",
        "projector.visualize_embeddings(log_dir, config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kyg-OXjfkM3"
      },
      "source": [
        "## Visualization using Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYwVkB-Jez87"
      },
      "source": [
        "# Now run tensorboard against on log data we just saved.\n",
        "%tensorboard --logdir {log_dir}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WV1PiqPTe3U8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
