{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist_classifier_custom.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMbT/lEHk1SrWPhTsgACui9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/magikerwin1993/Image-Clustering-tf2/blob/main/mnist_projector_with_custom_loop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HsYG65sCDyF"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "print('TF version:', tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPvKyy1JiD-l"
      },
      "source": [
        "# Training Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m95EzXMyBGhj"
      },
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDhAL9iYBFqg"
      },
      "source": [
        "LEARNING_RATE = 1e-2\n",
        "BATCH_SIZE = 128\n",
        "NUM_EPOCHS = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JMPxut4715n"
      },
      "source": [
        "## Data Preparation (using tf.data.Dataset)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJTQsjdx6zay"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Data normalization\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Adds channel dim for conv layer\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGFRNkfKKQ8h"
      },
      "source": [
        "def create_dataset(x, y, shuffle):\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
        "  dataset = dataset.batch(batch_size=BATCH_SIZE)\n",
        "  if shuffle:\n",
        "    dataset = dataset.shuffle(1000)\n",
        "  return dataset\n",
        "\n",
        "train_dataset = create_dataset(x_train, y_train, shuffle=True)\n",
        "eval_dataset = create_dataset(x_test, y_test, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcZJsps0LHhW"
      },
      "source": [
        "for batch_x, batch_y in train_dataset:\n",
        "  print(batch_x.shape, batch_y.shape)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytJ-nkNx94qi"
      },
      "source": [
        "## Model Definition (using Function API)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qHsY6HIDIw_"
      },
      "source": [
        "def create_classifier(input_shape, name):\n",
        "  input_tensor = tf.keras.layers.Input(input_shape, name='input')\n",
        "\n",
        "  out = input_tensor\n",
        "  out = tf.keras.layers.Conv2D(8, 3, 2, activation='relu', name='conv1') (out)\n",
        "  out = tf.keras.layers.Conv2D(16, 3, 2, activation='relu', name='conv2') (out)\n",
        "  out = tf.keras.layers.Flatten() (out)\n",
        "  out = tf.keras.layers.Dense(128, activation='relu', name='fc1') (out)\n",
        "  out = tf.keras.layers.Dropout(0.2) (out)\n",
        "  out = tf.keras.layers.Dense(64, activation='relu', name='fc2') (out)\n",
        "  out = tf.keras.layers.Dropout(0.2) (out)\n",
        "  out = tf.keras.layers.Dense(10, activation='softmax', name='fc3') (out)\n",
        "  return tf.keras.Model(inputs=[input_tensor], outputs=[out], name=name)\n",
        "\n",
        "classifier = create_classifier(input_shape=(28, 28, 1), name='classifier')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCQdGo5i9zHJ"
      },
      "source": [
        "classifier.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dTz4KQP-DSK"
      },
      "source": [
        "## Training (using tf.GradientTape)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5QX8fbNFZNF"
      },
      "source": [
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
        "acc_fn = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZYpvETRP66-"
      },
      "source": [
        "@tf.function\n",
        "def train_step(x, y):\n",
        "  with tf.GradientTape() as tape:\n",
        "    # Forward pass\n",
        "    pred = classifier(x, training=True)\n",
        "    loss = loss_fn(y, pred)\n",
        "\n",
        "  # Calculates gradients with respect to every trainable variable\n",
        "  grad = tape.gradient(loss, classifier.trainable_variables)\n",
        "  # Back propagation\n",
        "  optimizer.apply_gradients(zip(grad, classifier.trainable_variables))\n",
        "  return loss, acc_fn(y, pred)\n",
        "\n",
        "@tf.function\n",
        "def eval_step(x, y):    \n",
        "  # Forward pass\n",
        "  pred = classifier(x, training=True)\n",
        "  loss = loss_fn(y, pred)\n",
        "  acc_fn(y, pred)\n",
        "  return loss, acc_fn(y, pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhA94bqhFbkI"
      },
      "source": [
        "for epoch in range(NUM_EPOCHS):\n",
        "\n",
        "  train_loss_lst, train_acc_lst = [], []\n",
        "  for batch_x, batch_y in train_dataset:\n",
        "    loss, acc = train_step(batch_x, batch_y)\n",
        "    train_loss_lst.append(loss)\n",
        "    train_acc_lst.append(acc)\n",
        "\n",
        "  eval_loss_lst, eval_acc_lst = [], []\n",
        "  for batch_x, batch_y in eval_dataset:\n",
        "    loss, acc = eval_step(batch_x, batch_y)\n",
        "    eval_loss_lst.append(loss)\n",
        "    eval_acc_lst.append(acc)\n",
        "\n",
        "  train_loss = np.mean(train_loss_lst)\n",
        "  train_acc = np.mean(train_acc_lst)\n",
        "  eval_loss = np.mean(eval_loss_lst)\n",
        "  eval_acc = np.mean(eval_acc_lst)\n",
        "  print(f'Epoch {epoch}, loss: {train_loss:.4f}, accuracy: {train_acc:.4f},'\n",
        "        f' eval_loss: {eval_loss:.4f}, eval_accuracy: {eval_acc:.4f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tco_tcGMAT-j"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rlkgs-C-TP0"
      },
      "source": [
        "eval_loss_lst = []\n",
        "eval_acc_lst = []\n",
        "for batch_x, batch_y in eval_dataset:\n",
        "    loss, acc = eval_step(batch_x, batch_y)\n",
        "    eval_loss_lst.append(loss)\n",
        "    eval_acc_lst.append(acc)\n",
        "\n",
        "eval_loss = np.mean(eval_loss_lst)\n",
        "eval_acc = np.mean(eval_acc_lst)\n",
        "print('eval_loss:', eval_loss)\n",
        "print('eval_acc:', eval_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwngEPOqcGuc"
      },
      "source": [
        "# Visualization using Embedding Projector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "er9h9z3viJUF"
      },
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from tensorboard.plugins import projector\n",
        "\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VgGdKdxe90p"
      },
      "source": [
        "## Dataset for Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buW4xevhfAHl"
      },
      "source": [
        "VISUALIZATION_COUNT = 900\n",
        "\n",
        "x_test_ = x_test[:VISUALIZATION_COUNT]\n",
        "y_test_ = y_test[:VISUALIZATION_COUNT]\n",
        "print(x_test_.shape)\n",
        "print(y_test_.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPJE4Lt8fHPb"
      },
      "source": [
        "## Feature Extractor Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNv4lqRwcmK3"
      },
      "source": [
        "feature_extractor = tf.keras.Model(inputs=[classifier.input], \n",
        "                                   outputs=[classifier.get_layer('fc2').output])\n",
        "print(feature_extractor.output.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KcxPO-vfcN0"
      },
      "source": [
        "## Embedding Projector Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wp3G-dQucdPR"
      },
      "source": [
        "# Sets up a logs directory for Tensorboard\n",
        "log_dir='logs/mnist-embeddings'\n",
        "if not os.path.exists(log_dir):\n",
        "    os.makedirs(log_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mUkUkt2cyXB"
      },
      "source": [
        "# Saves labels to metadata.tsv\n",
        "classes = ['Zero', 'One', 'Two', 'Three', 'Four', 'Five', 'Six', 'Seven',\n",
        "           'Eight', 'Nine']\n",
        "with open(os.path.join(log_dir, 'metadata.tsv'), \"w\") as f:\n",
        "  for y in y_test_:\n",
        "    f.write(\"{}\\n\".format(classes[y]))\n",
        "\n",
        "\n",
        "images_pil = []\n",
        "for x, y in zip(x_test_, y_test_):\n",
        "  img_pil = Image.fromarray((x[..., 0] * 255).astype(np.uint8))\n",
        "  images_pil.append(img_pil)\n",
        "\n",
        "# Saves sprite image\n",
        "one_square_size = int(np.ceil(np.sqrt(VISUALIZATION_COUNT)))\n",
        "master_width = 28 * one_square_size\n",
        "master_height = 28 * one_square_size\n",
        "spriteimage = Image.new(\n",
        "    mode='RGB',\n",
        "    size=(master_width, master_height),\n",
        "    color=(0,0,0)  # fully transparent\n",
        ")\n",
        "\n",
        "for count, image in enumerate(images_pil):\n",
        "    div, mod = divmod(count, one_square_size)\n",
        "    h_loc = 28 * div\n",
        "    w_loc = 28 * mod\n",
        "    spriteimage.paste(image, (w_loc, h_loc))\n",
        "\n",
        "spriteimage.convert('RGB').save(os.path.join(log_dir, 'sprite.jpg'))\n",
        "spriteimage"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fmsJtoTdHV4"
      },
      "source": [
        "# Save the weights we want to analyze as a variable.\n",
        "features = feature_extractor(x_test_, training=False)\n",
        "features_var = tf.Variable(features)\n",
        "print(features_var.shape)\n",
        "\n",
        "# Create a checkpoint from embedding, the filename and key are the\n",
        "# name of the tensor.\n",
        "checkpoint = tf.train.Checkpoint(embedding=features_var)\n",
        "checkpoint.save(os.path.join(log_dir, \"embedding.ckpt\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0s-FAay6eF_L"
      },
      "source": [
        "# Sets up config\n",
        "config = projector.ProjectorConfig()\n",
        "embedding = config.embeddings.add()\n",
        "\n",
        "# The name of the tensor will be suffixed by `/.ATTRIBUTES/VARIABLE_VALUE`.\n",
        "embedding.tensor_name = \"embedding/.ATTRIBUTES/VARIABLE_VALUE\"\n",
        "embedding.metadata_path = 'metadata.tsv'\n",
        "embedding.sprite.image_path = 'sprite.jpg'\n",
        "embedding.sprite.single_image_dim.extend([28, 28])\n",
        "projector.visualize_embeddings(log_dir, config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kyg-OXjfkM3"
      },
      "source": [
        "## Visualization using Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYwVkB-Jez87"
      },
      "source": [
        "# Now run tensorboard against on log data we just saved.\n",
        "%tensorboard --logdir {log_dir}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1glXXtgliPE9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}